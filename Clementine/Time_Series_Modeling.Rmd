---
title: "VAR_Model_Clem_v1"
output: html_document
---

Steps for VAR Modeling - 

1. Seasonally adjust the data 
2. Individual ARIMA models, both time series needs to be I(1) process. 
    Interpret ACF, PACF, Residuals - White noise plots? 
3. ADF and KPSS test -> Not stationary. 
4. Johanessen test for cointegration. 
5. VAR Model - Train / test prediction error



Read seasonally adjusted data for modeling 

```{r}

library(tseries)
library(xlsx)
library(forecast)

setwd("/Users/kevalshah/Keval_Backup/University/UChicago/Capstone/Data/Data Clean up/Clean data to be used for Analysis")

options(java.parameters = "-Xmx1000m")

clem_data_social <- read.xlsx("clem_social_seasonally_adjusted_v1_average_weekly.xlsx", sheetName = "Seasonally Adjusted data")


# subset the data to have include observations that have both sales and social media data

clem_data_social_ts <- clem_data_social[1:260,]
head(clem_data_social_ts)


# Read seasonally adjusted Clementine sales volume data

clem_data_sales <- read.xlsx("clem_social_seasonally_adjusted_v1_average_weekly.xlsx", sheetName = "Clem Sales Volume")

myvars = c("Date", "salestszSeasonallyAdjusted")

clem_data_sales_ts <- clem_data_sales[myvars]
head(clem_data_sales_ts)

```

ARIMA Model 

```{r}
# Function
  fun.illustrate.2=function(data,nperiod,p,d,q,P,D,Q) {
    
    error.holdout = rep(0,nperiod)
    r.sq.error.holdout = rep(0, nperiod)
    
    
    for(i in 1:nperiod) {
      
      # Keeping the first week as hold out for i[1] and then increment until 52nd value
      # 52nd value = 52 week = 1 year i.e last year as hold out. 
      cutoff = length(data) - i
      #cutoff = cutoff - i
      
      #yvec.train=as.vector(data)[1:cutoff]
        if(cutoff >= nperiod) {
        yvec.train=as.vector(data)[1:cutoff]
        #break;
        yvec.hold=as.vector(data)[(cutoff+1):length(data)]
        #yvec.hold
        
        y=ts(yvec.train, start=2010, frequency=52)
        pred=predict(arima(y, order = c(p,d,q), seasonal = list(order = c(P,D,Q))),n.ahead=(length(data)-cutoff))
        # Predicted - Actual? or Actual - predicted.
        error.holdout[i]=mean((pred$pred-yvec.hold)^2)
        if(length(pred$pred) > 1) {r.sq.error.holdout[i] = (cor(pred$pred,yvec.hold))^2}
        #residuals.holdout[i] = yvec.hold - pred$pred 
      }
      
    }
    # Ignore R Square of the i = 1 when holdout is last week. 
    #return(list(error.holdout=error.holdout, Average = (error.holdout)^(1/length(error.holdout))))
    
    return(list(error.holdout=error.holdout, Average = mean(error.holdout), R.Squared = r.sq.error.holdout, length(pred$pred), length(yvec.hold)))
    
    #predict(arima(y, order = c(p,d,q), seasonal = list(order = c(P,D,Q))),n.ahead=12)$pred
    #predict(arima(y, order = c(p,d,q), seasonal = list(order = c(P,D,Q))),n.ahead=12)$pred)^2
    
  }
```


ARIMA for Clementine Social Media Mentions 

```{r}

# Clementines Social Media Mentions

f1<- fun.illustrate.2(clem_data_social$Total.social.media,52, 2,0,0,0,0,0)
f2<- fun.illustrate.2(clem_data_social$Total.social.media,52, 2,0,1,0,0,0)
f3<- fun.illustrate.2(clem_data_social$Total.social.media,52, 2,0,2,0,0,0)
f4<- fun.illustrate.2(clem_data_social$Total.social.media,52, 2,1,1,0,0,0)
f5<- fun.illustrate.2(clem_data_social$Total.social.media,52, 2,1,2,0,0,0)
f6<- fun.illustrate.2(clem_data_social$Total.social.media,52, 2,1,0,0,0,0)
f7<- fun.illustrate.2(clem_data_social$Total.social.media,52, 2,2,0,0,0,0)
f8<- fun.illustrate.2(clem_data_social$Total.social.media,52, 2,2,1,0,0,0)
f9<- fun.illustrate.2(clem_data_social$Total.social.media,52, 2,2,2,0,0,0)

f10<-fun.illustrate.2(clem_data_social$Total.social.media,52, 1,0,0,0,0,0)
f11<-fun.illustrate.2(clem_data_social$Total.social.media,52, 1,0,1,0,0,0)
f12<-fun.illustrate.2(clem_data_social$Total.social.media,52, 1,0,2,0,0,0)
f13<-fun.illustrate.2(clem_data_social$Total.social.media,52, 1,1,1,0,0,0)
f14<-fun.illustrate.2(clem_data_social$Total.social.media,52, 1,1,2,0,0,0)
f15<-fun.illustrate.2(clem_data_social$Total.social.media,52, 1,1,0,0,0,0)
f16<-fun.illustrate.2(clem_data_social$Total.social.media,52, 1,2,0,0,0,0)
f17<-fun.illustrate.2(clem_data_social$Total.social.media,52, 1,2,1,0,0,0)
f18<-fun.illustrate.2(clem_data_social$Total.social.media,52, 1,2,2,0,0,0)

f19<-fun.illustrate.2(clem_data_social$Total.social.media,52, 0,0,0,0,0,0)
f20<-fun.illustrate.2(clem_data_social$Total.social.media,52, 0,0,1,0,0,0)
f21<-fun.illustrate.2(clem_data_social$Total.social.media,52, 0,0,2,0,0,0)
f22<-fun.illustrate.2(clem_data_social$Total.social.media,52, 0,1,0,0,0,0)
f23<-fun.illustrate.2(clem_data_social$Total.social.media,52, 0,1,1,0,0,0)
f24<-fun.illustrate.2(clem_data_social$Total.social.media,52, 0,1,2,0,0,0)
f25<-fun.illustrate.2(clem_data_social$Total.social.media,52, 0,2,0,0,0,0)
f26<-fun.illustrate.2(clem_data_social$Total.social.media,52, 0,2,1,0,0,0)
f27<-fun.illustrate.2(clem_data_social$Total.social.media,52, 0,2,2,0,0,0)

# Concatenate
total.social_media <- c(f1$Average, f2$Average, f3$Average, f4$Average, f5$Average, f6$Average, f7$Average, f8$Average,f9$Average, f10$Average, f11$Average, f12$Average, f13$Average, f14$Average, f15$Average, f16$Average, f17$Average, f18$Average, f19$Average, f20$Average, f21$Average, f22$Average, f23$Average, f24$Average, f25$Average, f26$Average, f27$Average)

# Minimum
summary(total.social_media)
which.min(total.social_media)

# Auto ARIMA (2,1,2)
auto.total.social.media <- auto.arima(clem_data_social$Total.social.media)
auto.total.social.media
tsdisplay(residuals(auto.total.social.media))

# Forecast Auto ARIMA
auto.total.social.media.forecast <- forecast(auto.total.social.media, h=52)
plot(auto.total.social.media.forecast)

# Train and Test Split
clem_train_social_data_arima <- clem_data_social_ts[1:208,8]
head(clem_train_social_data_arima)

# Choosing Model 13 - ARIMA(1,1,1,0,0,0)
clem_train_social_arima_model <- Arima(clem_train_social_data_arima, order=c(1,1,1))
tsdisplay(residuals(clem_train_social_arima_model))

# Forecasting
forecast.clem.social.arima <- forecast(clem_train_social_arima_model, h=52)
forecast.clem.social.arima$mean
# Plot
plot(forecast(object=forecast.clem.social.arima,h="52"))
```


ARIMA for Clementine Sales Volume 


```{r}

# Clementines Sales Volume 

f1<- fun.illustrate.2(clem_data_sales_ts$salestszSeasonallyAdjusted,52, 2,0,0,0,0,0)
f2<- fun.illustrate.2(clem_data_sales_ts$salestszSeasonallyAdjusted,52, 2,0,1,0,0,0)
f3<- fun.illustrate.2(clem_data_sales_ts$salestszSeasonallyAdjusted,52, 2,0,2,0,0,0)
f4<- fun.illustrate.2(clem_data_sales_ts$salestszSeasonallyAdjusted,52, 2,1,1,0,0,0)
f5<- fun.illustrate.2(clem_data_sales_ts$salestszSeasonallyAdjusted,52, 2,1,2,0,0,0)
f6<- fun.illustrate.2(clem_data_sales_ts$salestszSeasonallyAdjusted,52, 2,1,0,0,0,0)
f7<- fun.illustrate.2(clem_data_sales_ts$salestszSeasonallyAdjusted,52, 2,2,0,0,0,0)
f8<- fun.illustrate.2(clem_data_sales_ts$salestszSeasonallyAdjusted,52, 2,2,1,0,0,0)
f9<- fun.illustrate.2(clem_data_sales_ts$salestszSeasonallyAdjusted,52, 2,2,2,0,0,0)

f10<-fun.illustrate.2(clem_data_sales_ts$salestszSeasonallyAdjusted,52, 1,0,0,0,0,0)
f11<-fun.illustrate.2(clem_data_sales_ts$salestszSeasonallyAdjusted,52, 1,0,1,0,0,0)
f12<-fun.illustrate.2(clem_data_sales_ts$salestszSeasonallyAdjusted,52, 1,0,2,0,0,0)
f13<-fun.illustrate.2(clem_data_sales_ts$salestszSeasonallyAdjusted,52, 1,1,1,0,0,0)
f14<-fun.illustrate.2(clem_data_sales_ts$salestszSeasonallyAdjusted,52, 1,1,2,0,0,0)
f15<-fun.illustrate.2(clem_data_sales_ts$salestszSeasonallyAdjusted,52, 1,1,0,0,0,0)
f16<-fun.illustrate.2(clem_data_sales_ts$salestszSeasonallyAdjusted,52, 1,2,0,0,0,0)
f17<-fun.illustrate.2(clem_data_sales_ts$salestszSeasonallyAdjusted,52, 1,2,1,0,0,0)
f18<-fun.illustrate.2(clem_data_sales_ts$salestszSeasonallyAdjusted,52, 1,2,2,0,0,0)

f19<-fun.illustrate.2(clem_data_sales_ts$salestszSeasonallyAdjusted,52, 0,0,0,0,0,0)
f20<-fun.illustrate.2(clem_data_sales_ts$salestszSeasonallyAdjusted,52, 0,0,1,0,0,0)
f21<-fun.illustrate.2(clem_data_sales_ts$salestszSeasonallyAdjusted,52, 0,0,2,0,0,0)
f22<-fun.illustrate.2(clem_data_sales_ts$salestszSeasonallyAdjusted,52, 0,1,0,0,0,0)
f23<-fun.illustrate.2(clem_data_sales_ts$salestszSeasonallyAdjusted,52, 0,1,1,0,0,0)
f24<-fun.illustrate.2(clem_data_sales_ts$salestszSeasonallyAdjusted,52, 0,1,2,0,0,0)
f25<-fun.illustrate.2(clem_data_sales_ts$salestszSeasonallyAdjusted,52, 0,2,0,0,0,0)
f26<-fun.illustrate.2(clem_data_sales_ts$salestszSeasonallyAdjusted,52, 0,2,1,0,0,0)
f27<-fun.illustrate.2(clem_data_sales_ts$salestszSeasonallyAdjusted,52, 0,2,2,0,0,0)

# Concatenate
total.sales.volume <- c(f1$Average, f2$Average, f3$Average, f4$Average, f5$Average, f6$Average, f7$Average, f8$Average,f9$Average, f10$Average, f11$Average, f12$Average, f13$Average, f14$Average, f15$Average, f16$Average, f17$Average, f18$Average, f19$Average, f20$Average, f21$Average, f22$Average, f23$Average, f24$Average, f25$Average, f26$Average, f27$Average)

# Minimum
summary(total.sales.volume)
which.min(total.sales.volume)

# Auto ARIMA (3,1,0)
auto.sales.volume <- auto.arima(clem_data_sales_ts$salestszSeasonallyAdjusted)
tsdisplay(residuals(auto.sales.volume))

# Forecast Auto ARIMA
auto.sales.volume.forecast <- forecast(auto.sales.volume, h=52)
plot(auto.sales.volume.forecast)

# Train and Test Split
clem_train_sales_data_arima <- clem_data_sales_ts[1:208,2]
head(clem_train_sales_data_arima)
# Choosing Model 17 - ARIMA(1,2,1,0,0,0)
clem_train_sales_arima_model <- Arima(clem_train_sales_data_arima, order=c(1,2,1))
tsdisplay(residuals(clem_train_sales_arima_model))

# Forecasting
forecast.clem.sales.arima <- forecast(clem_train_sales_arima_model, h=52)
forecast.clem.sales.arima$mean
# Plot
plot(forecast(object=forecast.clem.sales.arima,h="52"))
```


Both time series, clementine sales volume and social media are of I(1) OR > 1 process,
therefore the series is not stationary and has a trend and drift, and is not showing 
a tendency to return back to mean. 

Step 1: Check if the series is stationary. 

```{r}

sales.volume <- clem_data_sales_ts$salestszSeasonallyAdjusted
#d.sales.volume <- diff(sales.volume)
week <- clem_data_sales_ts$Date


# Descriptive statistics and plotting the data
summary(sales.volume)
#summary(d.sales.volume)

plot.ts(week, sales.volume, main = "Clementine sales volume", xlab = "Time", ylab = "Sales Volume")




#Based on the sales volume time series, there appears to be a linear trend.

#Therefore, for stationarity test we include a trend element in augmented dickey fuller test. 

#Augmented Dickey Fuller test for stationarity 




# Sales Volume 
# Null hypothesis H0: Non - Stationary 

#library(urca)
#summary(ur.df(y=sales.volume, lags = 52, type = "trend"))

adf.test(sales.volume, alternative = "stationary")

# KPSS test 
# Null hypothesis: Series is stationary around a constant mean
# Alternative: Series is non stationary 

kpss.test(sales.volume, null = "Trend")


```
ADF Test: 
With the p-value of 0.07, greater than significance level of 0.05 suggests that 
we fail reject the null hypothesis that the series is not stationary and unit root.
In other words, we have no evidence that the series is stationary. 

KPSS Test: 
At significance level of 5% or p-value > 0.05, we reject the 'Trend' null hypothesis that the series is stationary with a linear trend. In other words, we have 
no evidence that the series is stationary. 


:::::::::::::::::::::: SOCIAL MEDIA MENTIONS :::::::::::::::::::::::::::


```{r}

clem_total_social_media <- clem_data_social_ts$Total.social.media

#d.clem_blogs <- diff(clem_blogs)
week <- clem_data_social_ts$Analysis_Date


# Descriptive statistics and plotting the data
summary(clem_total_social_media)


plot(week, clem_total_social_media, main = "Clementine Total Social media mentions", xlab = "Time", ylab = "Total social media mentions")


# Augmented Dickey Fuller test for stationarity 
adf.test(clem_total_social_media, alternative = "stationary")


# KPSS test 
# Null hypothesis: Series is stationary.
# Alternative: Series is non stationary 

kpss.test(clem_total_social_media, null = "Level")

# Low p-value suggests that the series is Non - Stationary. We reject the null hypothesis of stationarity. 


```


Small p-value of 0.01, less than significance level of 0.05 suggests that 
we reject the null hypothesis that the series is stationary.


Now that we have established both series are not stationary and has a trend or drift component,
and are of I(1) or > process, we perform Johansen test for cointegration. 

```{r}

# Plot Sales and Sum Social Media Mentions

x1 <- clem_data_sales_ts$Date
y1 <- sales.volume
y2 <- clem_total_social_media

plot( x1, y1, type="l", col="red", main = "Clementines", xlab = "Date", lwd = "2.5")
par(new=TRUE)
plot( x1, y2, type="l", col="blue", ylab = "Sales & Social Media", lwd = "2.5")
legend("top", legend=c("Sales", "Social"), col=c("red", "blue"), lwd = 2.5, cex=0.8)

library("urca")

co.test.matrix <- cbind(sales.volume, clem_total_social_media)

CoIntegrationTest =ca.jo(co.test.matrix,type="trace",K=4,ecdet="none", spec="longrun")
summary(CoIntegrationTest)

```


With lag of k=4, we see that our test statistic (r <= 1) of 8.4 is higher than at least one of # the critical values at 10% confidence level 6.50, we can assume there is cointegration of r time series. 

#http://denizstij.blogspot.com/2013/11/cointegration-tests-adf-and-johansen.html 



Running VAR model for Multivariate time series. 

Multivariate time series analysis is used when one
wants to model and explain the interactions and comovements
among a group of time series variables

* http://faculty.washington.edu/ezivot/econ584/notes/multivariatetimeseries.pdf 

Granger Causality
One of the main uses of VAR models is forecasting.

The following intuitive notion of a variable’s forecasting
ability is due to Granger (1969).

• If a variable, or group of variables, y1 (social media mentions) is found to be helpful for predicting another variable (sales volume), or group of variables, y2 then y1 is said to Granger-cause y2; otherwise it is said to fail to Granger-cause y2.

VAR Model Building and Evaluation steps: 

1. Split Raw Clem sales and social data into train and validation (1 year). 
2. Based on the # of observation split the ARIMA values into train and validation (1 year). 
3. Run the VAR model on training set and forecast sales, social and measure the prediction accuracy by comparing the validation set. 
4. Make plots of sales, social and arima (benchmark)
5. Run the model on validation set. 
6. Make plots of sales, social and arima (benchmark)
7. Calculate the difference / lift / between sales arima forecasts and sales forecasts from var model. 


```{r}

library(vars)
library(astsa)

# Read Clementine Google Trends data in for exogenous variable in VAR model
setwd("/Users/kevalshah/Keval_Backup/University/UChicago/Capstone/Data/Data Clean up/Clean data to be used for Analysis")
clem_google_trends <- read.csv("Clem_Google_Trends_Searches.csv")

# Plot sales, social media and google trends

x1 <- clem_data_sales_ts$Date
y1 <- clem_data_sales_ts$salestszSeasonallyAdjusted
y2 <- clem_data_social_ts$Total.social.media
y3 <- clem_google_trends$clementine.Searches

#plot( x1, y1, type="l", col="red", main = "Clementines Sales, Social #Media and Google Trends", xlab = "Date", lwd = "2.5")
#par(new=TRUE)
#plot( x1, y2, type="l", col="blue", ylab = "Social", lwd = "2.5")
#par(new=TRUE)
#plot( x1, y3, type="l", col="orange", ylab = "Social & GT", lwd = "2.5")
#legend("top", legend=c("Sales", "Social"), col=c("red", "blue"), lwd = #2.5, cex=0.8)


# Run VAR Model on Training set 

length(clem_data_social_ts$Total.social.media)
length(clem_data_sales_ts$salestszSeasonallyAdjusted)
length(clem_data_sales_ts$Date)
length(clem_google_trends$clementine.Searches)

Train_clem_sales <- clem_data_sales_ts[1:208,2]
Train_clem_week <- clem_data_sales_ts[1:208,1]
Train_clem_social <- clem_data_social_ts[1:208,8]
Train_clem_google_trends <- clem_google_trends[1:208,3]

# Endogenous variables 
Train_VAR_clem <- cbind(Train_clem_sales, Train_clem_social)

#VAR Select
VARselect(Train_VAR_clem, lag.max = 10, type = "both", exogen = cbind(x3 =Train_clem_google_trends))

Train_VAR_model_clem <- VAR(Train_VAR_clem, p=2, type="both", exogen = cbind(x3 =Train_clem_google_trends))
summary(Train_VAR_model_clem)



```

The adjusted R-Squared of 87% for equation predicting sales as dependent variable and endogenous variables of social media and sales with lag order of 2 and exogenous variable of google trends with constant and trend deterministic variable 
indicates a good fit. 
On the other hand, the inverse, of predicting social media with sales as predictors has Adj. R-Squared of 67%.

Now, we fit our training model on our validation set and check the prediction error / accuracy. 

```{r}

# Run VAR Model on Validation / Test Set 

Test_clem_sales <- clem_data_sales_ts[209:260,2]
Test_clem_week <- clem_data_sales_ts[209:260,1]
Test_clem_social <- clem_data_social_ts[209:260,8]
Test_clem_google_trends <- clem_google_trends[209:260,3]

length(Test_clem_sales)
length(Test_clem_week)
length(Test_clem_social)
length(Test_clem_google_trends)

# Endogenous variables 
#Test_VAR_clem <- cbind(Test_clem_sales, Test_clem_social)

#VAR Select
#VARselect(Test_VAR_clem, lag.max = 10, type = "both", exogen = cbind(x3 =Test_clem_google_trends))

#Test_VAR_model_clem <- VAR(Test_VAR_clem, p=7, type="both", exogen = cbind(x3 =Test_clem_google_trends))
#summary(Test_VAR_model_clem)


```



```{r}

# Clementine prediction

var_train_forecasts <- predict(Train_VAR_model_clem, n.ahead = 52, ci = 0.95, dumvar = cbind(x3 =Test_clem_google_trends))

summary(var_train_forecasts)
head(var_train_forecasts)

plot(var_train_forecasts, type = "l", main = "Clem sales + social forecast using train model on test set")

# Check accuracy of our forecasts using train model on test data 

# Clem sales volume forecast
accuracy(var_train_forecasts$fcst$Train_clem_sales[,1], Test_clem_sales)

# Clem social media forecast
accuracy(var_train_forecasts$fcst$Train_clem_social[,1], Test_clem_social)

```


Plot Raw Sales and Social media with Forecasts 

```{r}

# Append raw + forecast
clem.sales.VAR.All <- append(Train_clem_sales, var_train_forecasts$fcst$Train_clem_sales[,1])
clem.social.VAR.All <- append(Train_clem_social, var_train_forecasts$fcst$Train_clem_social[,1])
clem.week.All <- append(Train_clem_week, Test_clem_week)

clem_df_total <- data.frame(clem.week.All, clem.sales.VAR.All, clem.social.VAR.All)


mar.default <- c(3,3,3,3) + 0.1
par(mar = mar.default + c(0, 1, 0, 0))
plot(clem_df_total[,1:2], type="l", 
     ylab="Sales Volume", xlab="Time (Year)", 
     lwd=3, main="Clementine: VAR Model", col="hotpink")
par(new=TRUE)
plot(clem_df_total[,3], type="l", col="darkolivegreen1", axes=FALSE, 
     ylab="", xlab="", lwd=3)
axis(4)
mtext("Social Media Mentions", side=4, line=+2, adj=0.5)
abline(v=208, lty=3, lwd=3)
legend("top", legend=c("Sales Volume", "Social Media Mentions"), 
       col=c("hotpink","darkolivegreen1"), lwd=3, cex=0.75)


```

Comparing sales prediction to ARIMA benchmark, make plots and calculate lift 

```{r}
# Calculate accuracy of arima sales forecast and VAR model sales forecast to actual sales values in 
# test set 
# Compare prediction error of each and calculate the lift obtained from prediction error. 


# Difference in Predictions Clementines

All_Clem_Forecasts <- cbind.data.frame(Test_week = as.Date(Test_clem_week), AR=forecast.clem.sales.arima$mean, VAR=var_train_forecasts$fcst$Train_clem_sales[,1],
                   ACTUAL=Test_clem_sales)
head(All_Clem_Forecasts)

# Calculate the RMSE. Predicted - Actual values. 
AR.error <- forecast.clem.sales.arima$mean - Test_clem_sales
ar.clem.sales.rmse <- sqrt(mean(AR.error^2))
# Calculate MAE
ar.clem.sales.mae <- mean(abs(AR.error))


# Calculate the RMSE. Predicted - Actual values. 
VAR.error <- var_train_forecasts$fcst$Train_clem_sales[,1] - Test_clem_sales
var.clem.sales.rmse <- sqrt(mean(VAR.error^2))
# Calculate MAE
var.clem.sales.mae <- mean(abs(VAR.error))


# Calculate Lift in prediction accuracy 
paste(round((((ar.clem.sales.rmse - var.clem.sales.rmse)/ar.clem.sales.rmse))*100, digits = 2), "%", sep = "")
paste(round((((ar.clem.sales.mae - var.clem.sales.mae)/ar.clem.sales.mae))*100, digits = 2), "%", sep = "")

# Create a table to compare RMSE and MAE 
accuracy_table <- matrix(c(1082234,790863.8,"26.92%",934652.2,672441,"28.05%"),ncol=3,byrow=TRUE)
colnames(accuracy_table) <- c("ARIMA","VAR", "Lift in Prediction accuracy")
rownames(accuracy_table) <- c("RMSE","MAE")
accuracy_table

# Append ARIMA sales data and forecasts 
clem.sales.arima.All <- append(clem_train_sales_data_arima, forecast.clem.sales.arima$mean)

clem.sales.actual.All <- append(Train_clem_sales, Test_clem_sales)

# Create a dataframe w Raw sales data, VAR Forecasts, ARIMA Forecasts and
# Test data. 

clem_df_total_final <- cbind.data.frame(clem.week.All, clem.sales.VAR.All, clem.sales.actual.All, clem.sales.arima.All)


mar.default <- c(3,3,3,3) + 0.1
par(mar = mar.default + c(0, 1, 0, 0))
plot(clem_df_total_final[,1:2], type="l", 
     ylab="", xlab="Time (Year)",
     lwd=3, main="Clementine Sales Volume Forecasts Comparison", col="hotpink")
par(new=TRUE)
# Actual data train + test
plot(clem_df_total_final[,3], type="l", col="darkolivegreen1", axes=FALSE, 
     ylab="", xlab="", lwd=3)
par(new=TRUE)
# ARIMA Forecast 
plot(clem_df_total_final[,4], type="l", col="blue", axes=FALSE, 
     ylab="", xlab="", lwd=3)

abline(v=208, lty=3, lwd=3)
legend("topleft", legend=c("VAR", "Actual", "ARIMA"), 
       col=c("hotpink","darkolivegreen1","blue"), lwd=3, cex=0.75)

```

Based on the above plot we can see that VAR model which includes 
social media and lagged sales volume as endogenours predictors and 
google trends as exogenous variables does predict better than ARIMA model
series predicting itself. 

```{r}
print(accuracy_table)
```

Based on Root mean squared error and Mean Absolute Error which calculates 
the prediction error (predicted - actual), from our train and test split, 
we see increased accuracy of more than 25% when using VAR models. 
 








